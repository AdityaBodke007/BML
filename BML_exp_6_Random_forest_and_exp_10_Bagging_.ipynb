{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwcXfDNQ3gBo8tFSvd/HtQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdityaBodke007/BML/blob/main/BML_exp_6_Random_forest_and_exp_10_Bagging_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "exp 6 Random Forest"
      ],
      "metadata": {
        "id": "xiok1FvRzaZK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VF5o0aps__B",
        "outputId": "5ce9658c-82e2-44bc-a33c-37a04ba05566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9649122807017544\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.95        43\n",
            "           1       0.96      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "exp 10 Bagging using Decision tree"
      ],
      "metadata": {
        "id": "mjFtu6o9z5WZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Use 'estimator' instead of 'base_estimator' for newer versions\n",
        "estimator = DecisionTreeClassifier()\n",
        "model = BaggingClassifier(estimator=estimator, n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yduNwmQxz3yh",
        "outputId": "e2fa03b0-2d8f-403f-eeae-be1b556471ba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.956140350877193\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94        43\n",
            "           1       0.96      0.97      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "exp 10 Using all Classifier **Bagging**"
      ],
      "metadata": {
        "id": "Zffr79MAxCE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define classifiers with preprocessing (scaling, imputation, feature selection, PCA)\n",
        "classifiers = {\n",
        "    \"KNN\": make_pipeline(\n",
        "        SimpleImputer(strategy='mean'),        # Handle missing values (mean imputation)\n",
        "        StandardScaler(),                      # Scale the features\n",
        "        SelectKBest(f_classif, k=20),          # Select top 20 features based on ANOVA F-value\n",
        "        PCA(n_components=10),                  # Apply PCA to reduce dimensionality (10 components)\n",
        "        KNeighborsClassifier(n_neighbors=5)\n",
        "    ),\n",
        "    \"Logistic Regression\": make_pipeline(\n",
        "        SimpleImputer(strategy='mean'),\n",
        "        StandardScaler(),\n",
        "        SelectKBest(f_classif, k=20),\n",
        "        PCA(n_components=10),\n",
        "        LogisticRegression(max_iter=1000)\n",
        "    ),\n",
        "    \"SVM\": make_pipeline(\n",
        "        SimpleImputer(strategy='mean'),\n",
        "        StandardScaler(),\n",
        "        SelectKBest(f_classif, k=20),\n",
        "        PCA(n_components=10),\n",
        "        SVC(probability=True)\n",
        "    ),\n",
        "    \"Decision Tree\": make_pipeline(\n",
        "        SimpleImputer(strategy='mean'),\n",
        "        SelectKBest(f_classif, k=20),         # Feature selection\n",
        "        DecisionTreeClassifier()\n",
        "    )\n",
        "}\n",
        "\n",
        "# Train and evaluate each classifier with Bagging\n",
        "for name, clf in classifiers.items():\n",
        "    print(f\"\\n=== {name} with Bagging ===\")\n",
        "    bagging_model = BaggingClassifier(estimator=clf, n_estimators=50, random_state=42)\n",
        "    bagging_model.fit(X_train, y_train)\n",
        "    y_pred = bagging_model.predict(X_test)\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDjqElEMw_Oh",
        "outputId": "76d5810c-ba30-43c6-c979-7c0e2d28c253"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== KNN with Bagging ===\n",
            "Accuracy: 0.9649122807017544\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95        43\n",
            "           1       0.97      0.97      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.96      0.96       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "\n",
            "=== Logistic Regression with Bagging ===\n",
            "Accuracy: 0.9824561403508771\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.98        43\n",
            "           1       0.97      1.00      0.99        71\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.99      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n",
            "\n",
            "=== SVM with Bagging ===\n",
            "Accuracy: 0.9649122807017544\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95        43\n",
            "           1       0.97      0.97      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.96      0.96       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "\n",
            "=== Decision Tree with Bagging ===\n",
            "Accuracy: 0.956140350877193\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94        43\n",
            "           1       0.96      0.97      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        }
      ]
    }
  ]
}